{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now start focussing towards using texts. You enjoy working text classifiers in your mail agent: it classifies letters and filters spam. Other applications include document classification, review classification, etc.\n",
    "\n",
    "Text classifiers are often used not as an individual task, but as part of bigger pipelines. For example, a voice assistant classifies your utterance to understand what you want (e.g., set the alarm, order a taxi or just chat) and passes your message to different models depending on the classifier's decision. Another example is a web search engine: it can use classifiers to identify the query language, to predict the type of your query (e.g., informational, navigational, transactional), to understand whether you what to see pictures or video in addition to documents, etc.\n",
    "\n",
    "Since most of the classification datasets assume that only one label is correct, we deal with this type of classification as the single-label classification. We mention multi-label classification in a separate notebook(Multi-Label Classification)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular datasets are for sentiment classification. They consist of reviews of movies, places or restaurants, and products. There are also datasets for question type classification and topic classification.\n",
    "\n",
    "To better understand typical classification tasks, we will use the imdb dataset through this week"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Text Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide a general view on classification and introduce the notation. This section applies to both classical and neural approaches.\n",
    "\n",
    "We will assume that we have a collection of documents with ground-truth labels. The input of a classifier is a document $x=(x_{1},...,x_{n})$ with tokens $(x_{1},...,x_{n})$, the output is a label $y\\in k$. Usually, a classifier estimates probability distribution over classes, and we want the probability of the correct class to be the highest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative and Discriminative Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Generative and Discriminative models](assets/gdm.jpeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification model can be either generative or discriminative.\n",
    "\n",
    "Generative models learn joint probability distribution of data $p(x,y)=p(x|y).p(y)$. To make a prediction given an input $x$, these models pick a class with the highest joint probability: $y= \\argmax\\limits_{k} p(x|y=k).p(y=k)$\n",
    " \n",
    "Discriminative models are interested only in the conditional probability $p(y|x)$, i.e. they learn only the border between classes. To make a prediction given an input $x$, these models pick a class with the highest conditional probability: $y= \\argmax\\limits_{k} p(y=k|x)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we consider classical approaches for text classification. They were developed long before neural networks became popular, and for small datasets can still perform comparably to neural models."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
